{"metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "pygments_lexer": "python3"}, "qubole": {"kernel_log_url": "https://us.qubole.com/jupyter-notebook-64279/qubole/api/v1/kernel_logs/5deabdb3-04ab-467f-b01e-995a939b96b3", "session_data": {"id": 72, "mode": "scoped", "spark_ui_url": "/cluster-proxy?clusterInst=7056996&encodedUrl=http%3A%2F%2F10.150.200.227%3A8088%2Fproxy%2Fapplication_1716350819274_0073%2F%3Fspark%3Dtrue", "driver_log_url": "/cluster-proxy?clusterInst=7056996&encodedUrl=http%3A%2F%2F10.150.200.149%3A8042%2Fnode%2Fcontainerlogs%2Fcontainer_1716350819274_0073_01_000001%2Fagaur"}}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "import numpy as np\nfrom pyspark.sql import SQLContext\nfrom pyspark.conf import SparkConf\nfrom pyspark.sql import SparkSession\nimport pandas as pd\n# import pandas.Series.tolist\nimport pandasql as ps\nimport boto3\nimport pyodbc\nimport io\nfrom datetime import date,timedelta\nfrom IPython.display import display\nimport json\nimport random\nimport time\nimport re\n### Custom Lib\npd.options.mode.chained_assignment = None\nfrom pyspark.sql.types import IntegerType,StructType,StructField,StringType\nfrom pyspark.sql.functions import lit,array, create_map, struct\nfrom pyspark.sql.functions import col, concat, regexp_extract, when,max as max_,min as min_\nfrom pyspark.sql.functions import date_format\nfrom pyspark.sql.functions import udf,col\nfrom datetime import datetime,timedelta\nfrom pymongo import MongoClient\nimport traceback\nimport ftplib", "metadata": {"qubole": {"execution_info": {"started_at": "2024-05-22T09:17:53.820700Z", "ended_at": "2024-05-22T09:17:56.725064Z", "user_email": "agaur@affinitiv.com", "cluster": "ADMT_API_PROD_CLUSTER", "clusterType": "cluster"}}, "trusted": true}, "execution_count": 1, "outputs": [{"name": "stdout", "text": "Kernel Id: 6892f790-4d3e-4dd2-b082-c73ab199a56c\n", "output_type": "stream"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>Name</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>72</td><td>scoped_agaur__affinitiv</td><td>application_1716350819274_0073</td><td>pyspark</td><td>idle</td><td><a class=\"jpq-ui-links\" data-url=\"/cluster-proxy?clusterInst=7056996&encodedUrl=http%3A%2F%2F10.150.200.227%3A8088%2Fproxy%2Fapplication_1716350819274_0073%2F%3Fspark%3Dtrue\" data-alt-url=\"\" data-action=\"spark-ui:open\" data-cluster-id=\"49246\" href=\"javascript:void(0)\" onClick=\"return false;\">Link</a></td><td><a class=\"jpq-ui-links\" data-url=\"/cluster-proxy?clusterInst=7056996&encodedUrl=http%3A%2F%2F10.150.200.149%3A8042%2Fnode%2Fcontainerlogs%2Fcontainer_1716350819274_0073_01_000001%2Fagaur\" data-alt-url=\"/cluster-proxy?clusterInst=7056996&encodedUrl=http%3A%2F%2F10.150.200.227%3A19888%2Fjobhistory%2Flogs%2F10.150.200.149%3A45454%2Fcontainer_1716350819274_0073_01_000001%2Fcontainer_1716350819274_0073_01_000001%2Fagaur\" data-action=\"driver-log:open\" data-cluster-id=\"49246\" href=\"javascript:void(0)\" onClick=\"return false;\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"name": "stdout", "text": "SparkSession available as 'spark'.\n", "output_type": "stream"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<div class=\"progress-ipython-shell\"></div>"}, "metadata": {}}]}, {"cell_type": "code", "source": "def errorcategorycode(errtext):\n    cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER=10.100.11.5;DATABASE=datalake;UID=datalake_prod;PWD=uqkHej49KENG')\n    querystring_details = \"select * from etl.error_category with(nolock)\"\n    error_code='MISC'\n    try:\n        dataframe_details = pd.read_sql(querystring_details, cnxn)\n        if len(dataframe_details) > 0:\n            for row in range(0,len(dataframe_details)):\n                error_keywords = dataframe_details['error_category_text'][row].split(\"|\")\n                if any(x in errtext for x in error_keywords):\n                    error_code = dataframe_details['error_category_code'][row]\n                    break\n    except:\n        pass\n    cnxn.close()\n    return error_code\nerrorcategorycode(Misc)\n\n\n#iiiiiiiiiii\n\n\n# this is ", "metadata": {"qubole": {"execution_info": {"started_at": "2024-05-22T09:23:12.482157Z", "ended_at": "2024-05-22T09:23:12.549253Z", "user_email": "agaur@affinitiv.com", "cluster": "ADMT_API_PROD_CLUSTER", "clusterType": "cluster"}}, "trusted": true}, "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<div class=\"progress-ipython-shell\"></div>"}, "metadata": {}}, {"name": "stderr", "text": "An error was encountered:\nname 'Misc' is not defined\nTraceback (most recent call last):\nNameError: name 'Misc' is not defined\n\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "def ", "metadata": {}, "execution_count": null, "outputs": []}]}